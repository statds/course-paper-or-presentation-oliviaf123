
\documentclass[12pt]{article}

%% preamble: Keep it clean; only include those you need
\usepackage{amsmath}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}

% for space filling
\usepackage{lipsum}
% highlighting hyper links
\usepackage[colorlinks=true, citecolor=blue]{hyperref}


%% meta data

\title{Attempting to predict Heart Disease using a classical decision tree machine learning method }
\author{Olivia Frillici\\
  Department of Statistics\\
  University of Connecticut
}

\begin{document}
\maketitle
\begin{abstract}
    Here is the abstract. 
    SOME NOTES: I do not have my abstract or introduction written yet. Also I am aware of the lack of references and pictures, for the first draft really wanted to focus on the writing and attempting to get all of the coding done. 
    \end{abstract}
    
    
    \section{Introduction}
    \label{sec:intro}
    
    Use this section to answer three questions:
    Why is the topic important/interesting?
    What has been done on this topic in the literature?
    What is your contribution?

    % roadmap
%The rest of the paper is organized as follows.
%The data will be presented in Section~\ref{sec:data}.
%The methods are described in Section~\ref{sec:meth}.
%The results are reported in Section~\ref{sec:resu}.
%A discussion concludes in Section~\ref{sec:disc}.


\section{Data}
\label{sec:data}

The data is acquired from kaggle and is the “largest heart disease data set available”. The creator of the data set combined a total of 5 datasets which had 11 overlapping variables. There are 918 observations. The variables in the data set are as follows: Age,measured in years, sex, male or female, ChestPainType, TA for typical angina, ATA for atypical angina, NAP for non-anginal pain, and ASY for asymptomatic, RestingBP, resting blood pressure measured in mm Hg, Cholesterol, serum cholesterol measured in mg/dL, FastingBS, fasting blood sugar, a binary variable where 1 equals FastingBS greater than 120 mg/dl and 0 otherwise, RestingECG, a binary variable for resting electrocardiogram results where Normal is Normal and ST represents having an ST wave abnormality, MaxHR, maximum heart rate achieved, Exercise angina, a binary yes or no variable, Oldpeak, a numeric value of ST wave depression, ST\_Slope, a categorical variable that places the slope of the peak exercise ST segment of a heartbeat wave into Up for upsloping, flat for flat, and down for downsloping, and lastly HeartDisease, the variable of interest, a binary variable where 1 represents an individual with heart disease and 0 for an individual that does not have heart disease. As expected with any dataset some data cleaning and variable visualization was required for developing and fitting the model. \par
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{heartdisease_and_gender.png}
  \caption{A comparative bar chart showing the distribution of gender and heart disease.}
  \label{fig:heartdisease_and_gender}
\end{figure}
Figure~\ref{fig:heartdisease_and_gender} shows that within this data set more females did not have heart disease than females who did. The opposite is evidently true for males, more males had heart disease in the data set than males who did not have heart disease. 
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{age_heartdisease.png}
  \caption{A comparative boxplot showing median age of individuals in the data set with and without heart disease.}
  \label{fig:age_heartdisease}
\end{figure}
In figure~\ref{fig:age_heartdisease} the Age and Heart Disease comparative boxplot shows that the median age for individuals who had heart disease is greater than the individuals who did not. 
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{cholesterol_heartdisease.png}
  \caption{A comparative boxplot showing median age of individuals in the data set with and without heart disease.}
  \label{fig:cholesterol_heartdisease}
\end{figure}
%CHANGE THE IMAGE PUT IN THE WRONG ONE
In figure~\ref{fig:cholesterol_heartdisease} the Cholesterol and Heart Disease comparative boxplots the medians for individuals who did and did not have heart disease seem to be very similar. Within the cholesterol data column there are over 100 observations with a value of 0, so when constructing the comparative boxplot the 0 values were removed so as not to extraordinarily skew the results.  
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{RestingBloodPressure_Heartdisease.png}
  \caption{A comparative boxplot showing resting blood pressure in mmHg of individuals in the data set with and without heart disease.}
  \label{fig:rbp_heartdisease}
\end{figure}
In figure~\ref{rbp_heartdisease} the resting blood pressure and heart disease comparative boxplots keep the same theme as figure~\ref{fig:cholesterol_heartdisease}. The median resting blood pressure for individuals with heart disease is slightly higher than for those without heart disease. However the difference is so mild it appears insignificant. 
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{FastingBloodSugar_HeartDisease.png}
  \caption{A proportional bar chart that shows frequency of individuals who have a fasting blood sugar value of greater than 120 mg/dl or less than within the groups of individuals who have heart disease and who don't.}
  \label{fig:FBS_heartdisease}
\end{figure}
Figure~\ref{fig:FBS_heartdisease} the fasting blood sugar and heart disease proportional bar chart shows that a very high proportion of the individuals that do not have heart disease also have a fasting blood sugar value of less than 120 mg/dl. The bar chart also shows that a large proportion of individuals who have heart disease also have a fasting blood sugar of less than 120 mg/dl. Finally this barchart shows that while individuals who have a fasting blood sugar that is greater than 120 mg/dl are in the minority there is a higher proportion of them who have heart disease than not. 
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{RestingECG_HeartDisease.png}
  \caption{A porportional bar chart that shows the frequency of individuals who have a resting electrocardiogram test result of normal or an elctrocardiogram result depicting an ST wave abnormality within the groups of individuals who have or do not have heart disease.}
  \label{fig:ECG_heartdisease}
\end{figure}
Figure~\ref{fig:ECG_heartdisease} shows that a majority of individuals both with and without heart disease have normal resting ECG outputs. This graph shows a similar trend to figure~\ref{fig:FBS_heartdisease} in that while having an ST wave abnormality is clearly in the minority a larger proportion of individuals affected by the abnormality also have heart disease.
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{MaxHR_HeartDisease.png}
  \caption{A comparative boxplot showing maximum heart rate achieved in beats per minute for individuals in the data set with and without heart disease.}
  \label{fig:maxHR_heartdisease}
\end{figure}
Figure~\ref{fig:maxHR_heartdisease}shows that the median max heart rate of individuals without heart disease is higher than that for individuals with heart disease. 
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{ExerciseInducedAngina_HeartDisease.png}
  \caption{A proportional bar chart that shows the frequency of individuals who have exercise induced angina within the groups of individuals who have or don't have heart disease.}
  \label{fig:EIA_heartdisease}
\end{figure}
Figure\ref{fig:EIA_heartdisease}shows that a high proportion of individuals who do not have heart disease also do not have exercise induced angina. Additionally, a high proportion of individuals who do have heart disease also have exercise induced angina. 
\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{STSlope_HeartDisease.png}
  \caption{A proportional barchart that shows the frequency of individuals who have an upward sloping, downward sloping, or flat ST segment of their peak exercise heart beat wave within the groups of individuals who have or don't have deart disease.}
  \label{fig:STslope_heartdisease}
\end{figure}
Finally figure~\ref{fig:STslope_heartdisease} shows that a high proportion of individuals who do not have heart disease have an upward slope on the ST segment of their peak exercise heart beat wave. Conversely a high proportion of individuals who have heart disease have a flat slope on the ST segment of their peak exercise heart beat wave. Additionally while in both the group with and without heart disease a downward sloping ST segment of the peak exercise heart beat wave was a very small minority of individuals, there was a higher proportion in individuals who had heart disease compared to those that did not.
PLEASE NOTE: STILL TRYING TO FIGURE OUT HOW TO OUTPUT THE GRAPHS IN ONE VISUAL SO THEY DONt TAKE UP PAGES AND PAGES OF SPACE. 



\section{Methods}
\label{sec:meth}


The aim for this paper is to create a classical decision tree machine learning model that given variable inputs can predict whether an individual has heart disease or not.
Three classical decision trees were created. One included all of the variables, one included all variables however the data had been modified to void any individuals that had a cholesterol level of 0 mg/dL. The final model created had been modified to include all variables except for chest pain type and ST slope.
Before any classical decision tree was made the data was split into 2 equal sized sets. One served as the training set and the other served as the validation or test set. A seed number of 4321 was used for the sample function in r so that results could be reproducible.
After the classical decision tree was made a determination if the tree needed to be trimmed by finding the smallest tree that had a cross validated error within one standard error of the minimum cross validated error.
To assess the model fit each model was validated with the validation set created at the beginning and the error rate was calculated by the sum of false negative and false positives over the total number of individuals in the set.


\section{Results}
\label{sec:resu}
As stated in the methods section, error rate was used to determine model fit and success.
The first model created, the one with all variables and all observations included produced an  error rate of .496732. This means that 49.67\% of the validation observations were misclassified by the model. After producing this model and investigating the cross validation table it was determined that no pruning was needed. Since the error rate was very large that motivated data modification and reassessment.
The next model that was made trimmed the number of observations by if an individual had a Cholesterol level of 0. This created a decision tree that needed to be pruned. Both the tree with 3 splits and 1 split met the requirements of falling within 1 standard error of the smallest cross validated error. The model was trimmed to have 3 splits because 1 split felt a little too simplistic. After pruning the tree the error rate was found to be .5201. This means that 52.01\% of the validation data was misclassified. This ended up being the worst performing model.
The final model created was modified to not include chest pain type because it is a variable that has 4 different classifications and usually variables that are numeric or can have binary classification work much better. Additionally ST slope was also removed because another variable in the data set provides a numeric measurement for this and the ST Slope variable, similar to the chest paint type variable, has 3 different classifications instead of 2. This tree also showed qualities which would make it a good candidate for pruning however, after attempting pruning in a bevvy of ways my program would seemingly not do any pruning. The error rate for this tree ended up being .4924. This means 49.24\% of the data in the validation set was misclassified. This model was surprisingly the one with the lowest error rate.

\section{Discussion}
\label{sec:disc}

In conclusion, the error rates of all three models hovered around 50\%. This is not a good result. Since the first error rate was so large in the first model with all of the variables I was led to try different models to see if they would improve the error rate. While each error rate is not identical I would argue that the differences between them are insignificant. I wanted to create a model without the cholesterol values of 0 because if the values reported are truly the serum levels of cholesterol it would be impossible if not extremely unhealthy for these to be 0. Originally I thought the creator of the data frame might have switched individuals who maybe didn’t have cholesterol levels to report from NA to 0 just so the usability and number of NA values was 0. Additionally after getting 2 bad results I decided to reasses and reflect, go through my notes and think about what could possibly make this model better. I found that these models work best with variables that are either numeric where a cut off point can be determined or strictly binary variables. This led me to take out the chest pain type because it had 4 buckets instead of 2. I also took out the ST slop variable because it seemed redundant and it also had 3 buckets of classification instead of 2. This model technically ended up having the smallest error rate but it still was around 50\%. 
Limitations in this paper mainly stem from the data source itself. Since there are over 100 individuals with claimed blood serum cholesterol levels of 0 when this is not medically possible I think that data point may have been misrepresented. Additionally even though there were a significant amount of variables provided I think the addition of more variables like weight, bmi, exercise frequency, or a quantitative measure of healthy lifestyle might make better less error prone models. I also think the method chosen to create the models was limiting. Since all of the models have a 50\% error rate I can conclude that classical decision trees might not be the best machine learning model for this data. Therefore widening the available model creation methods or at least testing other model creation methods and comparing error rates might be valuable to pursuing in the future. Finally while this data set was large and quite comprehensive with more time, money, and resources more individuals could be added to the data set.
Finally and most importantly, this study as it stands in its current state proves something very important: computers won\textsc{\char13}t be overtaking a doctor\textsc{\char13}s role anytime soon. The grueling years of training and studying still prevails over a tiny microchip in a motherboard. The results of this study however should not discourage the motivation of trying to come up with statistical models for medical outcomes. This paper should merely mark a moment in time. In the future as statistical knowledge increases and more patient data is released someday a computer may help a doctor in diagnosis.


%\bibliography{refs}
%\bibliographystyle{ama}

\end{document}